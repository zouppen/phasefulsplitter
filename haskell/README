Valmistelut
===========

Tarkista aluksi, mitä käyttöjärjestelmää käytät. Tässä on ohjeet
Debianille. Käyttöjärjestelmän tiedot saa näkyville seuraavalla
komennolla:

$ lsb_release -d

Debian 6.0 (squeeze) ja uudemmat
--------------------------------

Vaatii muutaman paketin, jotka saa paketinhallinnasta. Jos käytössäsi
on Debian Squeeze tai uudempi, voit komentaa:

# apt-get install ghc libghc6-binary-dev libghc6-url-dev libghc6-time-dev libghc6-zlib-dev libghc6-split-dev cabal-install

On olemassa myös paketti libghc6-regex-tdfa-dev, mutta se on
(toistaiseksi) vain unstablessa. Voit poimia sen apt-pinningillä tai
asentaa Cabalilla. Lisäksi paketti 'parallel' löytyy, mutta liian vanhana versiona. Siispä suosittelen seuraavaa:

$ cabal update
$ cabal install regex-tdfa
$ cabal install parallel

Siinä se, voit siirtyä kohtaan "Kääntäminen".

Debian 5.0 (lenny)
------------------

Vanhemmissa Debianeissa ensin pitää ladata ghc, sitten cabal ja lopuksi
cabalin avulla url-paketti. Seuraava ohje ei toimi välttämättä
pitkällä tähtäimellä, mutta näin minä asensin Lennyyn:

Ensin pääkäyttäjänä:

# apt-get install ghc libghc6-binary-dev libghc6-time-dev zlib1g-dev libghc6-parallel-dev
# wget http://ftp.fi.debian.org/debian/pool/main/h/haskell-cabal-install/cabal-install_0.8.0-1_amd64.deb http://ftp.fi.debian.org/debian/pool/main/libf/libffi/libffi5_3.0.9-1_amd64.deb
# dpkg -i libffi5_3.0.9-1_amd64.deb cabal-install_0.8.0-1_amd64.deb
# rm libffi5_3.0.9-1_amd64.deb cabal-install_0.8.0-1_amd64.deb

Ja tavallisena käyttäjänä:

$ cabal update
$ cabal install url
$ cabal install zlib
$ cabal install split
$ cabal install regex-tdfa
$ cabal install parallel

Kääntäminen
===========

$ ghc -O -o apache2data --make ApacheToData.hs
$ ghc --make -O -o classifier Classifier.hs

Käyttäminen
===========

Yhden tiedoston prosessointi:

$ ./apache2data /path/to/kotka/mobi.2009-07-07.gz outfile_name

Monen tiedoston prosessoinnissa voi käyttää
spawner-skriptiä. Parametrilista on seuraava:

  - mikä sovellus suoritetaan
  - kuinka monta prosessia ajetaan samanaikaisesti (esimerkin koneessa 8 ydintä,
    joten 9 samanaikaista prosessia)
  - mihin hakemistoon data kirjoitetaan (esimerkissä työhakemisto eli .)

Lisäksi ohjelmalle ohjataan (<) lista tiedostojen nimistä.

$ nice /path/to/spawner /path/to/apache2data 9 . <raw_file_list.txt

Käyttäminen, v2
===============

Tiedostolistan esikäsittely on täysin riippuvainen siitä, miten
logitiedostot on nimetty. Mitään suoraa ohjetta tähän on vaikea
antaa. Tässä käytetään ns. Ixonos-nimeämistä eli muotoa
'/polku/palvelimennimi/palvelunnimi.YYYY-MM-DD.gz'. Palvelut ovat
toisistaan irrallisia (ainakin analyysin mielekkyyden kannalta). Yksi
palvelu koostuu useammalla palvelimesta ja näillä oleva sisältö on
identtistä.

Aseta palvelunnimet tiedostoon:

$ cp server_map.txt.example server_map.txt
$ emacs server_map.txt  # or nano, vim ...

Tee tiedostolista käyttämällä findia esimerkiksi:

$ find /path/to/log -iname '*.gz' >tiedostolista.txt

Suoritetaan luokittelija, joka jakaa tiedostot eri palveluiden mukaan
ja tallentaa ne levylle etuliitteellä "ixonos."

$ ./classifier "tiedostolista.txt" "ixonos."

Voit myös antaa tiedostolistan syötteenä näin:

$ find ... | ./classifier "ixonos."

TODO muuta koodia tukemaan näitä tiedostoja.

Sarjallistuvuuden testaaminen
=============================

$ ghci ApacheLogReader.hs 
GHCi, version 6.10.4: http://www.haskell.org/ghc/  :? for help
Ok, modules loaded: ApacheLogReader, ApacheParser, Entry.
*ApacheLogReader> a <- readEntriesFromFile "/path/to/access.log.gz"
*ApacheLogReader> head $ filter (not.Entry.testBinary) a

Jos palauttaa tyhjän listan poikkeuksen, kaikki on kunnossa, muuten
näyttää ensimmäisen epäonnistuneen sarjallistamisen.
