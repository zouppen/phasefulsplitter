How to run on Linux:

Copy the example configuration file and modify it to your needs. If
you have just a one database, you just need to symlink the another
config to the first one. Later on, when you are processing from one
database to another, you can create two separate config files.

# cp database.conf.example database-in.conf
# ln -s database-in.conf database-out.conf
# cp process.conf.example process.conf
# emacs database-in.conf    # or nano, vim, ...

If you want to run this processing in distributed mode, you can set
portion-flag in the process.conf file. If you set portion=1-1000 it
will only process first thousand lines. In another client you can run
the processing with a different portion setting which doesn't overlap with 

You'll also need mysql support for Java. It's part of Debian, so in
Debian, you just need to get it:

# apt-get install libmysql-java 

Then, if you're using MySQL:

# export CLASSPATH=.:/usr/share/java/mysql-connector-java.jar

... and if you're using PostgreSQL:

# export CLASSPATH=.:/path/to/postgresql-8.4-701.jdbc4.jar

You are now ready to run this thing. Make sure you've got some log
files around and pipe the file names to Splitter with find or just a
temporary file list file and redirect its contents to Splitter with
'<'.

# java FileListPhase

Pedantic users may have a file list around and they want to get the
output to a log file, too:

# java Splitter <log_access-final.txt | tee splitter.log

How to see progress
===================

When running long jobs, you may want to see how many lines are
processed. First, find the process id of JVM running apacheparser and
execute:

$ kill -USR2 PID

It sends USR2 signal to JVM. Apacheparser traps the signal and then
progress status is dumped to stdout.